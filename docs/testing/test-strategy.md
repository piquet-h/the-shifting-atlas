# Test Strategy Guide

**Purpose:** Define when to use each test layer and provide guidelines for maintaining a healthy test pyramid.

**Audience:** Backend developers, test engineers, code reviewers

**Last Updated:** 2025-10-29

---

## Quick Reference

| Test Layer      | % of Tests | Speed      | Use For                                        | Don't Use For                |
| --------------- | ---------- | ---------- | ---------------------------------------------- | ---------------------------- |
| **Unit**        | 70-80%     | <5s total  | Pure logic, validation, transformations        | I/O, HTTP, DB operations     |
| **Integration** | 15-25%     | <10s total | Service layer, DI, repositories, HTTP handlers | Real database, external APIs |
| **E2E**         | 5-10%      | <90s total | Critical user journeys, real DB, performance   | Input validation, unit logic |

---

## The Test Pyramid

```
    /\
   /E2\      ‚Üê Few, slow, expensive (5-10%)
  /____\
 /      \
/  INT   \   ‚Üê Medium count, medium speed (15-25%)
/_________\
/          \
/   UNIT    \ ‚Üê Many, fast, cheap (70-80%)
/____________\
```

### Why This Matters

**Inverted Pyramid Anti-Pattern** (‚ùå BAD):

-   Too many E2E tests = slow CI, flaky tests, hard to debug
-   Too few unit tests = missed edge cases, hard to refactor

**Healthy Pyramid** (‚úÖ GOOD):

-   Fast feedback on logic errors (unit tests catch 70% of bugs)
-   Medium feedback on integration issues (integration tests catch 25%)
-   Slow feedback on production readiness (E2E tests validate 5%)

---

## Layer 1: Unit Tests

### Purpose

Test **pure logic** in isolation with all dependencies mocked.

### When to Write Unit Tests

‚úÖ **DO write unit tests for:**

-   Pure functions (input ‚Üí output, no side effects)
-   Business logic (calculation, validation, transformation)
-   Edge case handling (null, empty, boundary conditions)
-   Error formatting and response structure
-   Data model validation
-   Helper utilities

‚ùå **DON'T write unit tests for:**

-   Database queries (use integration tests)
-   HTTP request handling (use integration tests)
-   External API calls (use integration tests)
-   File I/O operations (use integration tests)

### Example: Good Unit Test

```typescript
// Unit test: Pure validation logic
import assert from 'node:assert'
import { test } from 'node:test'
import { validateDirection } from '../src/utils/directionValidator.js'

test('validateDirection returns error for invalid direction', () => {
    const result = validateDirection('zzz')
    assert.equal(result.valid, false)
    assert.ok(result.error)
    assert.ok(result.error.includes('Invalid direction'))
})

test('validateDirection accepts all cardinal directions', () => {
    const directions = ['north', 'south', 'east', 'west', 'up', 'down', 'in', 'out']
    for (const dir of directions) {
        const result = validateDirection(dir)
        assert.equal(result.valid, true, `${dir} should be valid`)
    }
})
```

### Fixture Pattern

```typescript
import { UnitTestFixture } from '../helpers/UnitTestFixture.js'

describe('My Module', () => {
    let fixture: UnitTestFixture

    beforeEach(async () => {
        fixture = new UnitTestFixture()
        await fixture.setup()
    })

    afterEach(async () => {
        await fixture.teardown()
    })

    test('example', async () => {
        const telemetry = await fixture.getTelemetryClient()
        // telemetry is MockTelemetryClient - check telemetry.events array
    })
})
```

### Characteristics

-   ‚ö° **Speed:** <50ms per test
-   üéØ **Scope:** Single function or class
-   üîß **Mocking:** All dependencies mocked
-   üìä **Coverage:** 70-80% of total tests

---

## Layer 2: Integration Tests

### Purpose

Test **service layer integration** with in-memory repositories and mocked external dependencies.

### When to Write Integration Tests

‚úÖ **DO write integration tests for:**

-   Service orchestration (multiple components working together)
-   Repository contracts (interface compliance)
-   HTTP request/response flows (envelope structure)
-   Telemetry emission (event tracking)
-   DI container setup (dependency resolution)
-   Complex business workflows (multi-step processes)
-   Database-like operations (using in-memory implementations)

‚ùå **DON'T write integration tests for:**

-   Real database performance (use E2E)
-   Real database concurrency (use E2E)
-   External API calls (mock them)
-   Pure logic (use unit tests)

### Example: Good Integration Test

```typescript
// Integration test: Service layer with in-memory repositories
import assert from 'node:assert'
import { afterEach, beforeEach, describe, test } from 'node:test'
import { IntegrationTestFixture } from '../helpers/IntegrationTestFixture.js'
import { seedTestWorld } from '../helpers/seedTestWorld.js'

describe('Move Validation', () => {
    let fixture: IntegrationTestFixture

    beforeEach(async () => {
        fixture = new IntegrationTestFixture('memory')
        await fixture.setup()
    })

    afterEach(async () => {
        await fixture.teardown()
    })

    test('missing exit returns error', async () => {
        const locationRepo = await fixture.getLocationRepository()
        const playerRepo = await fixture.getPlayerRepository()

        // Seed test world
        const { locations } = await seedTestWorld({
            locationRepository: locationRepo,
            playerRepository: playerRepo
        })

        // Try to move in direction with no exit
        const northLocation = locations.find((l) => l.name.includes('North'))
        const result = await locationRepo.move(northLocation!.id, 'north')

        // Assert error response
        assert.equal(result.status, 'error')
        assert.ok(result.reason.includes('No exit'))
    })
})
```

### Fixture Modes

```typescript
// Mode 1: Memory (in-memory repositories)
fixture = new IntegrationTestFixture('memory')

// Mode 2: Mock (all mocked, like unit tests)
fixture = new IntegrationTestFixture('mock')

// Don't use 'cosmos' in integration tests - that's for E2E
```

### Characteristics

-   ‚ö° **Speed:** <100ms per test
-   üéØ **Scope:** Multiple components, service layer
-   üîß **Mocking:** External dependencies mocked, in-memory persistence
-   üìä **Coverage:** 15-25% of total tests

---

## Layer 3: E2E Tests

### Purpose

Test **critical user journeys** with real database and production-like infrastructure.

### When to Write E2E Tests

‚úÖ **DO write E2E tests for:**

-   Critical user journeys (golden path: move ‚Üí look ‚Üí interact)
-   Real database behavior (Cosmos DB latency, throttling, consistency)
-   Production readiness validation (can it handle real traffic?)
-   Performance benchmarking (p95 latency targets)
-   Cross-service integration (multiple services working together)
-   Database concurrency (race conditions, locking)
-   Infrastructure validation (partition keys, connection pooling)

‚ùå **DON'T write E2E tests for:**

-   Input validation (use unit or integration tests)
-   Error handling (use unit or integration tests)
-   Edge cases (use unit tests)
-   Business logic permutations (use unit tests)
-   Telemetry emission (use integration tests)

### Example: Good E2E Test

```typescript
// E2E test: Real Cosmos DB with performance validation
import assert from 'node:assert'
import { afterEach, beforeEach, describe, test } from 'node:test'
import { E2ETestFixture } from './E2ETestFixture.js'

describe('E2E Integration Tests - Cosmos DB', () => {
    let fixture: E2ETestFixture

    beforeEach(async () => {
        if (process.env.PERSISTENCE_MODE !== 'cosmos') {
            console.log('‚äò Skipping E2E tests (PERSISTENCE_MODE != cosmos)')
            return
        }
        fixture = new E2ETestFixture()
        await fixture.setup()
    })

    afterEach(async () => {
        if (fixture) {
            await fixture.teardown()
        }
    })

    test('multi-hop traversal with performance validation', async () => {
        if (process.env.PERSISTENCE_MODE !== 'cosmos') return

        const { locations } = await fixture.seedTestWorld()
        const locationRepo = await fixture.getLocationRepository()

        // Move 1: Hub ‚Üí North
        const start1 = Date.now()
        const move1 = await locationRepo.move(locations[0].id, 'north')
        fixture.trackPerformance('move-operation', Date.now() - start1)

        assert.equal(move1.status, 'ok')

        // Move 2: North ‚Üí South (back to hub)
        const start2 = Date.now()
        const move2 = await locationRepo.move(move1.location!.id, 'south')
        fixture.trackPerformance('move-operation', Date.now() - start2)

        assert.equal(move2.status, 'ok')
        assert.equal(move2.location!.id, locations[0].id)

        // Validate performance target
        const p95 = fixture.getP95Latency('move-operation')
        assert.ok(p95! < 500, `Move p95 latency ${p95}ms exceeds 500ms target`)
    })
})
```

### Fixture Setup

```typescript
import { E2ETestFixture } from './E2ETestFixture.js'

// E2ETestFixture automatically uses 'cosmos' mode
fixture = new E2ETestFixture()
await fixture.setup()

// Seed test world (creates locations with exits)
const { locations } = await fixture.seedTestWorld()

// Player creation is now explicit (no automatic demo player on seed)
// Example (if needed for a test path):
// const playerRepository = await fixture.getPlayerRepository()
// const { record: player } = await playerRepository.getOrCreate()

// Track performance metrics
fixture.trackPerformance('operation-name', durationMs)
const p95 = fixture.getP95Latency('operation-name')
```

### Characteristics

-   ‚ö° **Speed:** 500ms-5s per test
-   üéØ **Scope:** Full stack, real infrastructure
-   üîß **Mocking:** Nothing mocked (uses real Cosmos DB)
-   üìä **Coverage:** 5-10% of total tests
-   üí∞ **Cost:** Azure Cosmos DB RU consumption

---

## Decision Tree: Which Test Layer?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ What are you testing?                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Pure logic?     ‚îÇ
    ‚îÇ (no I/O)        ‚îÇ
    ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ YES      ‚îÇ NO
      ‚ñº          ‚ñº
   UNIT       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   TEST       ‚îÇ Needs real DB?   ‚îÇ
              ‚îÇ (concurrency,    ‚îÇ
              ‚îÇ performance,     ‚îÇ
              ‚îÇ Cosmos-specific) ‚îÇ
              ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
                ‚îÇ YES         ‚îÇ NO
                ‚ñº             ‚ñº
              E2E         INTEGRATION
              TEST          TEST
```

### Examples

**Scenario: Validate direction input**

-   Decision: Pure logic validation
-   **Answer: Unit Test** ‚úÖ

**Scenario: Test move handler response structure**

-   Decision: HTTP envelope structure, no real DB needed
-   **Answer: Integration Test** ‚úÖ

**Scenario: Test multi-player concurrent moves**

-   Decision: Requires real database concurrency
-   **Answer: E2E Test** ‚úÖ

**Scenario: Test telemetry event emission**

-   Decision: Can use MockTelemetryClient, no real App Insights needed
-   **Answer: Integration Test** ‚úÖ

**Scenario: Test Cosmos DB throttling (429) retry**

-   Decision: Requires real Cosmos DB SDK behavior
-   **Answer: E2E Test** ‚úÖ

---

## Common Pitfalls

### ‚ùå Anti-Pattern #1: Unit Testing I/O

```typescript
// BAD: Unit test trying to test database operations
test('should save player to database', async () => {
    const player = { id: '123', name: 'Test' }
    await database.savePlayer(player) // ‚Üê Real database call in unit test!
    const saved = await database.getPlayer('123')
    assert.equal(saved.name, 'Test')
})
```

**Fix:** Move to integration test with in-memory repository or E2E test with real database.

### ‚ùå Anti-Pattern #2: E2E Testing Edge Cases

```typescript
// BAD: E2E test for edge case validation
test('should reject empty player name', async () => {
    const result = await createPlayer({ name: '' }) // ‚Üê This is input validation!
    assert.equal(result.error, 'Name is required')
})
```

**Fix:** Move to unit test for validation logic or integration test for HTTP envelope.

### ‚ùå Anti-Pattern #3: Integration Testing Without Mocks

```typescript
// BAD: Integration test hitting real external API
test('should fetch weather data', async () => {
    const weather = await weatherAPI.fetch('Seattle') // ‚Üê Real API call!
    assert.ok(weather.temperature)
})
```

**Fix:** Mock external API in integration test or move to E2E with recorded fixtures.

---

## Test Coverage Guidelines

### What to Measure

‚úÖ **DO measure:**

-   Line coverage (goal: >80%)
-   Branch coverage (goal: >75%)
-   Function coverage (goal: >90%)
-   Critical path coverage (goal: 100%)

‚ùå **DON'T obsess over:**

-   100% coverage (diminishing returns)
-   Coverage of trivial getters/setters
-   Coverage of third-party libraries

### Coverage Targets by Layer

| Layer       | Target Coverage | Priority                           |
| ----------- | --------------- | ---------------------------------- |
| Unit        | 80-90%          | High - catch logic bugs early      |
| Integration | 60-70%          | Medium - verify service contracts  |
| E2E         | 30-40%          | Low - validate critical paths only |

**Total Coverage:** Aim for 70-80% overall

---

## Performance Targets

### Unit Tests

-   **Per test:** <50ms
-   **Total suite:** <5 seconds
-   **Failure impact:** Block PR if failing

### Integration Tests

-   **Per test:** <100ms
-   **Total suite:** <10 seconds
-   **Failure impact:** Block PR if failing

### E2E Tests

-   **Per test:** 500ms-5s
-   **Total suite:** <90 seconds
-   **Failure impact:** Block merge to main if failing

### Performance Degradation Detection

```typescript
// Track performance in E2E tests
fixture.trackPerformance('operation-name', durationMs)

// Validate against targets
const p95 = fixture.getP95Latency('operation-name')
assert.ok(p95 < TARGET_MS, `p95 latency ${p95}ms exceeds target`)
```

---

## CI/CD Integration

### PR Checks (Fast Feedback)

-   Lint & Typecheck
-   Unit Tests
-   Integration Tests
-   **Total: <2 minutes**

### E2E Checks (Comprehensive Validation)

-   Run on: PR + merge to main
-   Execution Time: <90 seconds
-   Cost: Minimal (dedicated test database)

### Nightly Checks (Future)

-   Extended E2E scenarios
-   Load testing
-   Performance regression detection

---

## Code Review Checklist

When reviewing test PRs, check:

-   [ ] Is the test at the right layer? (Unit/Integration/E2E)
-   [ ] Does it test one thing? (Single responsibility)
-   [ ] Is it deterministic? (No flakiness)
-   [ ] Does it have clear assertions? (Not just "doesn't throw")
-   [ ] Is setup/teardown handled properly? (Fixtures)
-   [ ] Are mocks used appropriately? (Not in E2E)
-   [ ] Is performance tracked? (E2E tests only)
-   [ ] Is it documented? (Clear test names, comments for complex logic)

---

## Migration Guide

### Moving Tests Between Layers

**From E2E ‚Üí Integration:**

1. Change fixture from `E2ETestFixture` to `IntegrationTestFixture('memory')`
2. Remove performance tracking (unless needed)
3. Remove Cosmos DB specific assertions
4. Keep same test logic and assertions
5. Verify test still passes with in-memory repositories

**From Integration ‚Üí Unit:**

1. Change fixture from `IntegrationTestFixture` to `UnitTestFixture`
2. Extract pure logic into standalone function
3. Remove repository/service dependencies
4. Test function directly with example inputs
5. Mock any remaining dependencies

**From Unit ‚Üí Integration:**

1. Identify I/O or multi-component interaction
2. Add `IntegrationTestFixture` setup
3. Use in-memory repositories for persistence
4. Keep logic tests separate (don't merge)

---

## Troubleshooting

### "My test is too slow"

-   **If unit test:** You're probably doing I/O ‚Üí move to integration
-   **If integration test:** Check if you're hitting real database ‚Üí use in-memory
-   **If E2E test:** This is expected; ensure it tests something unique

### "My test is flaky"

-   **Random failures:** Check for shared state between tests
-   **Timing issues:** Remove `sleep()`, use proper async/await
-   **Database issues:** Ensure cleanup in teardown, use unique test IDs

### "Not sure which layer to use"

-   **Ask:** Can this be tested without I/O? ‚Üí Unit
-   **Ask:** Does it need real database behavior? ‚Üí E2E
-   **Otherwise:** Integration

---

## Further Reading

-   `backend/test/TEST_FIXTURE_GUIDE.md` - Detailed fixture usage
-   `backend/test/e2e/README.md` - E2E test setup and configuration
-   `docs/testing/test-inventory-analysis.md` - Complete test inventory

---

**Remember:** A healthy test pyramid is not about the absolute numbers, but about the right tests at the right layer. When in doubt, start with a unit test and move up only if needed.
