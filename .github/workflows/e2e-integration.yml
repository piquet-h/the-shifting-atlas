name: E2E Integration Tests

# E2E tests run against real Cosmos DB
# Policy: Run on merge to main (post-merge validation), not on every PR (cost/time tradeoff)
# See: Issue #170, docs/developer-workflow/local-dev-setup.md

on:
  push:
    branches: [main]
    paths:
      - 'backend/**'
      - 'shared/**'
      - '.github/workflows/e2e-integration.yml'
  workflow_dispatch:
    inputs:
      run_e2e:
        description: 'Force E2E test run'
        required: false
        type: boolean
        default: true
  # Nightly schedule for extended E2E scenarios
  schedule:
    - cron: '0 2 * * *' # 2 AM UTC daily

permissions:
  contents: read
  packages: read

concurrency:
  group: e2e-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e-cosmos:
    name: E2E Tests (Cosmos DB)
    runs-on: ubuntu-latest
    timeout-minutes: 15 # Suite target: <90s, allow buffer for setup
    env:
      NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      PERSISTENCE_MODE: cosmos
      # Use test-specific Cosmos endpoints if available, fallback to production
      # Note: In production CI, configure test database secrets for isolation
      COSMOS_GREMLIN_ENDPOINT: ${{ secrets.COSMOS_GREMLIN_ENDPOINT_TEST || secrets.COSMOS_GREMLIN_ENDPOINT }}
      COSMOS_GREMLIN_DATABASE: ${{ secrets.COSMOS_GREMLIN_DATABASE_TEST || secrets.COSMOS_GREMLIN_DATABASE || 'game' }}
      COSMOS_GREMLIN_GRAPH: ${{ secrets.COSMOS_GREMLIN_GRAPH_TEST || secrets.COSMOS_GREMLIN_GRAPH || 'world' }}
      COSMOS_SQL_ENDPOINT: ${{ secrets.COSMOS_SQL_ENDPOINT_TEST || secrets.COSMOS_SQL_ENDPOINT }}
      COSMOS_SQL_DATABASE: ${{ secrets.COSMOS_SQL_DATABASE_TEST || secrets.COSMOS_SQL_DATABASE || 'game-docs' }}
      COSMOS_SQL_CONTAINER_PLAYERS: players
      COSMOS_SQL_CONTAINER_INVENTORY: inventory
      COSMOS_SQL_CONTAINER_LAYERS: descriptionLayers
      COSMOS_SQL_CONTAINER_EVENTS: worldEvents
      # Cosmos auth via Azure credentials
      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: |
            shared/package-lock.json
            backend/package-lock.json
          registry-url: 'https://npm.pkg.github.com'
          scope: '@piquet-h'
          always-auth: true

      - name: Install shared dependencies
        run: cd shared && npm ci

      - name: Install backend dependencies
        run: cd backend && npm ci

      - name: Build shared
        run: cd shared && npm run build

      - name: Build backend
        run: cd backend && npm run build

      - name: Run E2E Tests
        id: e2e_tests
        run: |
          cd backend
          set +e  # Don't exit on error
          npm run test:e2e 2>&1 | tee e2e-output.log
          E2E_EXIT_CODE=${PIPESTATUS[0]}
          echo "exit_code=$E2E_EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0  # Always succeed to allow post-processing

      - name: Check E2E test result
        run: |
          EXIT_CODE="${{ steps.e2e_tests.outputs.exit_code }}"
          if grep -q "⊘ Skipping E2E tests" backend/e2e-output.log; then
            echo "⚠️ E2E tests were skipped (likely missing Cosmos configuration)"
            echo "::warning::E2E tests skipped - check Cosmos DB configuration"
            exit 0
          elif [ "$EXIT_CODE" != "0" ]; then
            echo "❌ E2E tests failed (exit code: $EXIT_CODE)"
            exit 1
          else
            echo "✅ E2E tests passed"
          fi

      - name: Extract Performance Metrics
        if: always()
        run: |
          if [ -f backend/e2e-output.log ]; then
            echo '## E2E Performance Metrics' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            # Extract performance metrics with more robust patterns
            grep -E "(p95 latency:|completed in [0-9]+ms|Completed [0-9]+ rapid lookups)" backend/e2e-output.log >> $GITHUB_STEP_SUMMARY 2>/dev/null || true
            grep -E "✓ (Seeded|First LOOK|Move|LOOK) .*(in |p95:) [0-9]+ms" backend/e2e-output.log >> $GITHUB_STEP_SUMMARY 2>/dev/null || true
            
            # If no metrics found, indicate that
            if ! grep -q "ms" $GITHUB_STEP_SUMMARY; then
              echo "No performance metrics found in test output" >> $GITHUB_STEP_SUMMARY
            fi
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload E2E test output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-test-output
          path: backend/e2e-output.log
          if-no-files-found: ignore

  e2e-summary:
    name: E2E Summary
    needs: [e2e-cosmos]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Generate Summary
        run: |
          echo '## E2E Integration Tests Summary' >> $GITHUB_STEP_SUMMARY
          echo '* Cosmos DB Tests: ${{ needs.e2e-cosmos.result }}' >> $GITHUB_STEP_SUMMARY
          echo '' >> $GITHUB_STEP_SUMMARY
          echo '**Note:** E2E tests run on merge to main (post-merge validation)' >> $GITHUB_STEP_SUMMARY
          echo 'and nightly (2 AM UTC) for cost optimization.' >> $GITHUB_STEP_SUMMARY
          echo '' >> $GITHUB_STEP_SUMMARY
          echo 'Performance targets (p95):' >> $GITHUB_STEP_SUMMARY
          echo '- Full suite: <90s' >> $GITHUB_STEP_SUMMARY
          echo '- Single move: <500ms' >> $GITHUB_STEP_SUMMARY
          echo '- LOOK query: <200ms' >> $GITHUB_STEP_SUMMARY
